{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-Procesamiento de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#EXPLICACION DE QUE VOY A AHCER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "standard_cols = [\n",
    "    'id_recorrido', 'duracion_recorrido', 'fecha_origen_recorrido',\n",
    "    'id_estacion_origen', 'nombre_estacion_origen', 'direccion_estacion_origen',\n",
    "    'long_estacion_origen', 'lat_estacion_origen',\n",
    "    'fecha_destino_recorrido', 'id_estacion_destino', 'nombre_estacion_destino',\n",
    "    'direccion_estacion_destino', 'long_estacion_destino', 'lat_estacion_destino',\n",
    "    'id_usuario', 'modelo_bicicleta', 'genero'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Dataset Trips 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trips_2020 = pd.read_csv('../data/raw/recorridos/trips_2020.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño del dataset original: (2415597, 18)\n",
      "Features del archivo:\n",
      "['Unnamed: 0', 'Id_recorrido', 'duracion_recorrido', 'fecha_origen_recorrido', 'id_estacion_origen', 'nombre_estacion_origen', 'direccion_estacion_origen', 'long_estacion_origen', 'lat_estacion_origen', 'fecha_destino_recorrido', 'id_estacion_destino', 'nombre_estacion_destino', 'direccion_estacion_destino', 'long_estacion_destino', 'lat_estacion_destino', 'id_usuario', 'modelo_bicicleta', 'género']\n"
     ]
    }
   ],
   "source": [
    "print(f'Tamaño del dataset original: {df_trips_2020.shape}')\n",
    "print(\"Features del archivo:\")\n",
    "print(df_trips_2020.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renombrar columnas para que coincidan con el formato estándar\n",
    "df_trips_2020 = df_trips_2020.rename(columns={\n",
    "    'Id_recorrido': 'id_recorrido',\n",
    "    'género': 'genero'\n",
    "})\n",
    "\n",
    "# Eliminar columnas basura\n",
    "df_trips_2020 = df_trips_2020.drop(columns=['Unnamed: 0', 'X'], errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columnas reordenadas correctamente.\n"
     ]
    }
   ],
   "source": [
    "missing_cols = [col for col in standard_cols if col not in df_trips_2020.columns]\n",
    "if missing_cols:\n",
    "    print(\"Faltan las siguientes columnas:\", missing_cols)\n",
    "else:\n",
    "    df_trips_2020 = df_trips_2020[standard_cols]\n",
    "    print(\"Columnas reordenadas correctamente.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.1) Saco las comas en \"duracion_recorrido\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trips_2020['duracion_recorrido'] = df_trips_2020['duracion_recorrido'].str.replace(',', '', regex=False)\n",
    "df_trips_2020['duracion_recorrido'] = pd.to_numeric(df_trips_2020['duracion_recorrido'], errors='coerce')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.2) Extraigo solo números de IDs y convertir a enteros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in ['id_recorrido', 'id_usuario', 'id_estacion_origen', 'id_estacion_destino']:\n",
    "    df_trips_2020[col] = df_trips_2020[col].str.extract(r'(\\d+)')[0].astype('Int64')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.3) Convierto fechas a datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trips_2020['fecha_origen_recorrido'] = pd.to_datetime(df_trips_2020['fecha_origen_recorrido'], errors='coerce')\n",
    "df_trips_2020['fecha_destino_recorrido'] = pd.to_datetime(df_trips_2020['fecha_destino_recorrido'], errors='coerce')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.4) Arreglo latitud y longitud destino, las separo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "coords_split = df_trips_2020['lat_estacion_destino'].str.split(',', expand=True)\n",
    "\n",
    "df_trips_2020['lat_estacion_destino'] = pd.to_numeric(coords_split[0], errors='coerce')\n",
    "df_trips_2020['long_estacion_destino'] = pd.to_numeric(coords_split[1], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo guardado exitosamente en data/processed/recorridos/trips_2020.csv\n"
     ]
    }
   ],
   "source": [
    "df_trips_2020.to_csv('../data/processed/recorridos/trips_2020.csv', index=False)\n",
    "print(\"Archivo guardado exitosamente en data/processed/recorridos/trips_2020.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Dataset Trips 2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/27/qwsyx_4n4pjc_cljhqtfcjbh0000gn/T/ipykernel_62423/1486298880.py:1: DtypeWarning: Columns (17,18) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_trips_2021 = pd.read_csv('../data/raw/recorridos/trips_2021.csv')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño del dataset original: (2860091, 19)\n",
      "Features del archivo:\n",
      "['Unnamed: 0', 'Id_recorrido', 'duracion_recorrido', 'fecha_origen_recorrido', 'id_estacion_origen', 'nombre_estacion_origen', 'direccion_estacion_origen', 'long_estacion_origen', 'lat_estacion_origen', 'fecha_destino_recorrido', 'id_estacion_destino', 'nombre_estacion_destino', 'direccion_estacion_destino', 'long_estacion_destino', 'lat_estacion_destino', 'id_usuario', 'modelo_bicicleta', 'género', 'Género']\n"
     ]
    }
   ],
   "source": [
    "df_trips_2021 = pd.read_csv('../data/raw/recorridos/trips_2021.csv')\n",
    "print(f'Tamaño del dataset original: {df_trips_2021.shape}')\n",
    "print(\"Features del archivo:\")\n",
    "print(df_trips_2021.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columnas después de limpiar:\n",
      "['id_recorrido', 'duracion_recorrido', 'fecha_origen_recorrido', 'id_estacion_origen', 'nombre_estacion_origen', 'direccion_estacion_origen', 'long_estacion_origen', 'lat_estacion_origen', 'fecha_destino_recorrido', 'id_estacion_destino', 'nombre_estacion_destino', 'direccion_estacion_destino', 'long_estacion_destino', 'lat_estacion_destino', 'id_usuario', 'modelo_bicicleta', 'genero']\n",
      "Columnas reordenadas correctamente.\n"
     ]
    }
   ],
   "source": [
    "# Renombrar columnas para que coincidan con el formato estándar\n",
    "df_trips_2021 = df_trips_2021.rename(columns={\n",
    "    'Id_recorrido': 'id_recorrido',\n",
    "    'género': 'genero'\n",
    "})\n",
    "\n",
    "# Eliminar columnas basura\n",
    "df_trips_2021 = df_trips_2021.drop(columns=['Unnamed: 0', 'Género'], errors='ignore')\n",
    "print(\"Columnas después de limpiar:\")\n",
    "print(df_trips_2021.columns.tolist())\n",
    "\n",
    "missing_cols = [col for col in standard_cols if col not in df_trips_2021.columns]\n",
    "if missing_cols:\n",
    "    print(\"Faltan las siguientes columnas:\", missing_cols)\n",
    "else:\n",
    "    df_trips_2021 = df_trips_2021[standard_cols]\n",
    "    print(\"Columnas reordenadas correctamente.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trips_2021['duracion_recorrido'] = df_trips_2021['duracion_recorrido'].str.replace(',', '', regex=False)\n",
    "df_trips_2021['duracion_recorrido'] = pd.to_numeric(df_trips_2021['duracion_recorrido'], errors='coerce')\n",
    "for col in ['id_recorrido', 'id_usuario', 'id_estacion_origen', 'id_estacion_destino']:\n",
    "    df_trips_2021[col] = df_trips_2021[col].str.extract(r'(\\d+)')[0].astype('Int64')\n",
    "df_trips_2021['fecha_origen_recorrido'] = pd.to_datetime(df_trips_2021['fecha_origen_recorrido'], errors='coerce')\n",
    "df_trips_2021['fecha_destino_recorrido'] = pd.to_datetime(df_trips_2021['fecha_destino_recorrido'], errors='coerce')\n",
    "\n",
    "coords_split = df_trips_2021['lat_estacion_destino'].str.split(',', expand=True)\n",
    "\n",
    "df_trips_2021['lat_estacion_destino'] = pd.to_numeric(coords_split[0], errors='coerce')\n",
    "df_trips_2021['long_estacion_destino'] = pd.to_numeric(coords_split[1], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo guardado exitosamente en data/processed/recorridos/trips_2021.csv\n"
     ]
    }
   ],
   "source": [
    "df_trips_2021.to_csv('../data/processed/recorridos/trips_2021.csv', index=False)\n",
    "print(\"Archivo guardado exitosamente en data/processed/recorridos/trips_2021.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Dataset Trips 2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño del dataset original: (2922805, 19)\n",
      "Features del archivo:\n",
      "['Unnamed: 0', 'X', 'Id_recorrido', 'duracion_recorrido', 'fecha_origen_recorrido', 'id_estacion_origen', 'nombre_estacion_origen', 'direccion_estacion_origen', 'long_estacion_origen', 'lat_estacion_origen', 'fecha_destino_recorrido', 'id_estacion_destino', 'nombre_estacion_destino', 'direccion_estacion_destino', 'long_estacion_destino', 'lat_estacion_destino', 'id_usuario', 'modelo_bicicleta', 'Género']\n"
     ]
    }
   ],
   "source": [
    "df_trips_2022 = pd.read_csv('../data/raw/recorridos/trips_2022.csv')\n",
    "print(f'Tamaño del dataset original: {df_trips_2022.shape}')\n",
    "print(\"Features del archivo:\")\n",
    "print(df_trips_2022.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columnas después de limpiar:\n",
      "['id_recorrido', 'duracion_recorrido', 'fecha_origen_recorrido', 'id_estacion_origen', 'nombre_estacion_origen', 'direccion_estacion_origen', 'long_estacion_origen', 'lat_estacion_origen', 'fecha_destino_recorrido', 'id_estacion_destino', 'nombre_estacion_destino', 'direccion_estacion_destino', 'long_estacion_destino', 'lat_estacion_destino', 'id_usuario', 'modelo_bicicleta', 'genero']\n",
      "Columnas reordenadas correctamente.\n"
     ]
    }
   ],
   "source": [
    "# Renombrar columnas para que coincidan con el formato estándar\n",
    "df_trips_2022 = df_trips_2022.rename(columns={\n",
    "    'Id_recorrido': 'id_recorrido',\n",
    "    'Género': 'genero'\n",
    "})\n",
    "\n",
    "# Eliminar columnas basura\n",
    "df_trips_2022 = df_trips_2022.drop(columns=['Unnamed: 0', 'X'], errors='ignore')\n",
    "print(\"Columnas después de limpiar:\")\n",
    "print(df_trips_2022.columns.tolist())\n",
    "\n",
    "missing_cols = [col for col in standard_cols if col not in df_trips_2022.columns]\n",
    "if missing_cols:\n",
    "    print(\"Faltan las siguientes columnas:\", missing_cols)\n",
    "else:\n",
    "    df_trips_2022 = df_trips_2022[standard_cols]\n",
    "    print(\"Columnas reordenadas correctamente.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trips_2022['duracion_recorrido'] = df_trips_2022['duracion_recorrido'].str.replace(',', '', regex=False)\n",
    "df_trips_2022['duracion_recorrido'] = pd.to_numeric(df_trips_2022['duracion_recorrido'], errors='coerce')\n",
    "for col in ['id_recorrido', 'id_usuario', 'id_estacion_origen', 'id_estacion_destino']:\n",
    "    df_trips_2022[col] = df_trips_2022[col].str.extract(r'(\\d+)')[0].astype('Int64')\n",
    "df_trips_2022['fecha_origen_recorrido'] = pd.to_datetime(df_trips_2022['fecha_origen_recorrido'], errors='coerce')\n",
    "df_trips_2022['fecha_destino_recorrido'] = pd.to_datetime(df_trips_2022['fecha_destino_recorrido'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo guardado exitosamente en data/processed/recorridos/trips_2022.csv\n"
     ]
    }
   ],
   "source": [
    "df_trips_2022.to_csv('../data/processed/recorridos/trips_2022.csv', index=False)\n",
    "print(\"Archivo guardado exitosamente en data/processed/recorridos/trips_2022.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Dataset Trips 2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño del dataset original: (2622331, 18)\n",
      "Features del archivo:\n",
      "['Unnamed: 0', 'Id_recorrido', 'duracion_recorrido', 'fecha_origen_recorrido', 'id_estacion_origen', 'nombre_estacion_origen', 'direccion_estacion_origen', 'long_estacion_origen', 'lat_estacion_origen', 'fecha_destino_recorrido', 'id_estacion_destino', 'nombre_estacion_destino', 'direccion_estacion_destino', 'long_estacion_destino', 'lat_estacion_destino', 'id_usuario', 'modelo_bicicleta', 'género']\n"
     ]
    }
   ],
   "source": [
    "df_trips_2023 = pd.read_csv('../data/raw/recorridos/trips_2023.csv')\n",
    "print(f'Tamaño del dataset original: {df_trips_2023.shape}')\n",
    "print(\"Features del archivo:\")\n",
    "print(df_trips_2023.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columnas después de limpiar:\n",
      "['id_recorrido', 'duracion_recorrido', 'fecha_origen_recorrido', 'id_estacion_origen', 'nombre_estacion_origen', 'direccion_estacion_origen', 'long_estacion_origen', 'lat_estacion_origen', 'fecha_destino_recorrido', 'id_estacion_destino', 'nombre_estacion_destino', 'direccion_estacion_destino', 'long_estacion_destino', 'lat_estacion_destino', 'id_usuario', 'modelo_bicicleta', 'genero']\n",
      "Columnas reordenadas correctamente.\n"
     ]
    }
   ],
   "source": [
    "df_trips_2023 = df_trips_2023.rename(columns={\n",
    "    'Id_recorrido': 'id_recorrido',\n",
    "    'género': 'genero'\n",
    "})\n",
    "\n",
    "# Eliminar columnas basura\n",
    "df_trips_2023 = df_trips_2023.drop(columns=['Unnamed: 0'], errors='ignore')\n",
    "print(\"Columnas después de limpiar:\")\n",
    "print(df_trips_2023.columns.tolist())\n",
    "\n",
    "missing_cols = [col for col in standard_cols if col not in df_trips_2023.columns]\n",
    "if missing_cols:\n",
    "    print(\"Faltan las siguientes columnas:\", missing_cols)\n",
    "else:\n",
    "    df_trips_2023 = df_trips_2023[standard_cols]\n",
    "    print(\"Columnas reordenadas correctamente.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trips_2023['duracion_recorrido'] = df_trips_2023['duracion_recorrido'].str.replace(',', '', regex=False)\n",
    "df_trips_2023['duracion_recorrido'] = pd.to_numeric(df_trips_2023['duracion_recorrido'], errors='coerce')\n",
    "for col in ['id_recorrido', 'id_usuario', 'id_estacion_origen', 'id_estacion_destino']:\n",
    "    df_trips_2023[col] = df_trips_2023[col].str.extract(r'(\\d+)')[0].astype('Int64')\n",
    "df_trips_2023['fecha_origen_recorrido'] = pd.to_datetime(df_trips_2023['fecha_origen_recorrido'], errors='coerce')\n",
    "df_trips_2023['fecha_destino_recorrido'] = pd.to_datetime(df_trips_2023['fecha_destino_recorrido'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo guardado exitosamente en data/processed/recorridos/trips_2023.csv\n"
     ]
    }
   ],
   "source": [
    "df_trips_2023.to_csv('../data/processed/recorridos/trips_2023.csv', index=False)\n",
    "print(\"Archivo guardado exitosamente en data/processed/recorridos/trips_2023.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5) Dataset Trips 2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trips_2024 = pd.read_csv('../data/raw/recorridos/trips_2024.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño del dataset original: (3559284, 17)\n",
      "Features del archivo:\n",
      "['id_recorrido', 'duracion_recorrido', 'fecha_origen_recorrido', 'id_estacion_origen', 'nombre_estacion_origen', 'direccion_estacion_origen', 'long_estacion_origen', 'lat_estacion_origen', 'fecha_destino_recorrido', 'id_estacion_destino', 'nombre_estacion_destino', 'direccion_estacion_destino', 'long_estacion_destino', 'lat_estacion_destino', 'id_usuario', 'modelo_bicicleta', 'genero']\n"
     ]
    }
   ],
   "source": [
    "print(f'Tamaño del dataset original: {df_trips_2024.shape}')\n",
    "print(\"Features del archivo:\")\n",
    "print(df_trips_2024.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filas restantes luego del filtro: 2155645\n"
     ]
    }
   ],
   "source": [
    "df_trips_2024['fecha_origen_recorrido'] = pd.to_datetime(df_trips_2024['fecha_origen_recorrido'], errors='coerce')\n",
    "# Filtrar: solo fechas hasta agosto 2024 inclusive\n",
    "df_trips_2024 = df_trips_2024[df_trips_2024['fecha_origen_recorrido'].dt.month <= 8]\n",
    "print(f\"Filas restantes luego del filtro: {df_trips_2024.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo guardado exitosamente en data/processed/recorridos/trips_2024.csv\n"
     ]
    }
   ],
   "source": [
    "df_trips_2024.to_csv('../data/processed/recorridos/trips_2024.csv', index=False)\n",
    "print(\"Archivo guardado exitosamente en data/processed/recorridos/trips_2024.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Dataset Usuarios 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo guardado exitosamente en data/processed/usuarios/usuarios_2020.csv\n"
     ]
    }
   ],
   "source": [
    "df_usuarios_2020 = pd.read_csv('../data/raw/usuarios/usuarios_ecobici_2020.csv')\n",
    "df_usuarios_2020.drop(columns=['Customer.Has.Dni..Yes...No.'], inplace=True)\n",
    "df_usuarios_2020['fecha_alta'] = pd.to_datetime(df_usuarios_2020['fecha_alta'], errors='coerce')\n",
    "\n",
    "df_usuarios_2020 = df_usuarios_2020.rename(columns={\n",
    "    'ID_usuario': 'id_usuario',\n",
    "    'genero_usuario': 'genero'\n",
    "})\n",
    "df_usuarios_2020['edad_usuario'] = pd.to_numeric(df_usuarios_2020['edad_usuario'], errors='coerce').astype('Int64')\n",
    "df_usuarios_2020.to_csv('../data/processed/usuarios/usuarios_2020.csv', index=False)\n",
    "print(\"Archivo guardado exitosamente en data/processed/usuarios/usuarios_2020.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Dataset Usuarios 2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo guardado exitosamente en data/processed/usuarios/usuarios_2021.csv\n"
     ]
    }
   ],
   "source": [
    "df_usuarios_2021 = pd.read_csv('../data/raw/usuarios/usuarios_ecobici_2021.csv')\n",
    "df_usuarios_2021.drop(columns=['Customer.Has.Dni..Yes...No.'], inplace=True)\n",
    "df_usuarios_2021['fecha_alta'] = pd.to_datetime(df_usuarios_2021['fecha_alta'], errors='coerce')\n",
    "\n",
    "df_usuarios_2021 = df_usuarios_2021.rename(columns={\n",
    "    'ID_usuario': 'id_usuario',\n",
    "    'genero_usuario': 'genero'\n",
    "})\n",
    "df_usuarios_2021['edad_usuario'] = pd.to_numeric(df_usuarios_2021['edad_usuario'], errors='coerce').astype('Int64')\n",
    "df_usuarios_2021.to_csv('../data/processed/usuarios/usuarios_2021.csv', index=False)\n",
    "print(\"Archivo guardado exitosamente en data/processed/usuarios/usuarios_2021.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Dataset Usuarios 2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo guardado exitosamente en data/processed/usuarios/usuarios_2022.csv\n"
     ]
    }
   ],
   "source": [
    "df_usuarios_2022 = pd.read_csv('../data/raw/usuarios/usuarios_ecobici_2022.csv')\n",
    "df_usuarios_2022.drop(columns=['Customer.Has.Dni..Yes...No.'], inplace=True)\n",
    "df_usuarios_2022['fecha_alta'] = pd.to_datetime(df_usuarios_2022['fecha_alta'], errors='coerce')\n",
    "\n",
    "\n",
    "df_usuarios_2022 = df_usuarios_2022.rename(columns={\n",
    "    'ID_usuario': 'id_usuario',\n",
    "    'genero_usuario': 'genero'\n",
    "})\n",
    "df_usuarios_2022['edad_usuario'] = pd.to_numeric(df_usuarios_2022['edad_usuario'], errors='coerce').astype('Int64')\n",
    "df_usuarios_2022.to_csv('../data/processed/usuarios/usuarios_2022.csv', index=False)\n",
    "print(\"Archivo guardado exitosamente en data/processed/usuarios/usuarios_2022.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Dataset Usuarios 2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo guardado exitosamente en data/processed/usuarios/usuarios_2023.csv\n"
     ]
    }
   ],
   "source": [
    "df_usuarios_2023 = pd.read_csv('../data/raw/usuarios/usuarios_ecobici_2023.csv',low_memory=False)\n",
    "df_usuarios_2023.drop(columns=['Customer.Has.Dni..Yes...No.'], inplace=True)\n",
    "df_usuarios_2023['fecha_alta'] = pd.to_datetime(df_usuarios_2023['fecha_alta'], errors='coerce')\n",
    "\n",
    "df_usuarios_2023 = df_usuarios_2023.rename(columns={\n",
    "    'ID_usuario': 'id_usuario',\n",
    "    'genero_usuario': 'genero'\n",
    "})\n",
    "df_usuarios_2023['edad_usuario'] = pd.to_numeric(df_usuarios_2023['edad_usuario'], errors='coerce').astype('Int64')\n",
    "df_usuarios_2023.to_csv('../data/processed/usuarios/usuarios_2023.csv', index=False)\n",
    "print(\"Archivo guardado exitosamente en data/processed/usuarios/usuarios_2023.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5) Dataset Usuarios 2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filas restantes luego del filtro: 115204\n",
      "Archivo guardado exitosamente en data/processed/usuarios/usuarios_2024.csv\n"
     ]
    }
   ],
   "source": [
    "df_usuarios_2024 = pd.read_csv('../data/raw/usuarios/usuarios_ecobici_2024.csv')\n",
    "df_usuarios_2024['fecha_alta'] = pd.to_datetime(df_usuarios_2024['fecha_alta'], errors='coerce')\n",
    "df_usuarios_2024 = df_usuarios_2024.rename(columns={\n",
    "    'genero_usuario': 'genero'\n",
    "})\n",
    "df_usuarios_2024 = df_usuarios_2024[df_usuarios_2024['fecha_alta'].dt.month <= 8]\n",
    "print(f\"Filas restantes luego del filtro: {df_usuarios_2024.shape[0]}\")\n",
    "df_usuarios_2024.to_csv('../data/processed/usuarios/usuarios_2024.csv', index=False)\n",
    "print(\"Archivo guardado exitosamente en data/processed/usuarios/usuarios_2024.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Union de datasets de años a un solo dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de filas combinadas: 7700781\n",
      "Archivo guardado exitosamente en: data/preprocessed/trips.csv\n"
     ]
    }
   ],
   "source": [
    "files = [\n",
    "    '../data/processed/recorridos/trips_2022.csv',\n",
    "    '../data/processed/recorridos/trips_2023.csv',\n",
    "    '../data/processed/recorridos/trips_2024.csv'\n",
    "]\n",
    "\n",
    "dfs = [pd.read_csv(f) for f in files]\n",
    "trips = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "print(f\"Total de filas combinadas: {trips.shape[0]}\")\n",
    "\n",
    "trips.to_csv('../data/processed/trips.csv', index=False)\n",
    "print(\"Archivo guardado exitosamente en: data/preprocessed/trips.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de filas combinadas: 546010\n",
      "Archivo guardado exitosamente en: data/preprocessed/usuarios.csv\n"
     ]
    }
   ],
   "source": [
    "files = [\n",
    "    '../data/processed/usuarios/usuarios_2020.csv',\n",
    "    '../data/processed/usuarios/usuarios_2021.csv',\n",
    "    '../data/processed/usuarios/usuarios_2022.csv',\n",
    "    '../data/processed/usuarios/usuarios_2023.csv',\n",
    "    '../data/processed/usuarios/usuarios_2024.csv'\n",
    "]\n",
    "\n",
    "dfs = [pd.read_csv(f) for f in files]\n",
    "trips = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "print(f\"Total de filas combinadas: {trips.shape[0]}\")\n",
    "\n",
    "trips.to_csv('../data/processed/usuarios.csv', index=False)\n",
    "print(\"Archivo guardado exitosamente en: data/preprocessed/usuarios.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13, 14, 15, 17, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 35, 36, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 62, 63, 64, 65, 66, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 98, 99, 101, 102, 104, 105, 106, 107, 110, 111, 112, 114, 115, 116, 117, 118, 119, 120, 121, 122, 124, 126, 127, 128, 130, 131, 132, 134, 135, 137, 138, 141, 143, 144, 146, 148, 149, 150, 151, 152, 153, 154, 155, 156, 158, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 210, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 238, 239, 240, 241, 242, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 332, 333, 335, 336, 337, 338, 339, 340, 341, 342, 343, 345, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 358, 359, 361, 362, 363, 364, 366, 367, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 441, 442, 443, 444, 447, 448, 449]\n",
      "Cantidad de estaciones: 399\n"
     ]
    }
   ],
   "source": [
    "# Eliminar filas con NaN solo en las columnas de estaciones\n",
    "df_2020_filtrado = df_trips_2020.dropna(subset=['id_estacion_origen', 'id_estacion_destino'])\n",
    "\n",
    "# Crear conjunto de estaciones únicas\n",
    "estaciones = sorted(set(df_2020_filtrado['id_estacion_origen']).union(\n",
    "                    set(df_2020_filtrado['id_estacion_destino'])))\n",
    "\n",
    "n_est = len(estaciones)\n",
    "print(estaciones)\n",
    "print(f'Cantidad de estaciones: {n_est}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 3, 4, 5, 6, 7, 8, 9, 12, 13, 14, 17, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 32, 33, 35, 36, 38, 41, 42, 43, 44, 45, 46, 48, 49, 50, 51, 54, 56, 58, 59, 60, 61, 63, 64, 65, 66, 68, 69, 70, 71, 73, 74, 75, 76, 77, 79, 80, 82, 83, 84, 85, 86, 87, 89, 91, 92, 93, 94, 95, 96, 98, 99, 101, 104, 105, 107, 111, 112, 114, 116, 117, 118, 120, 121, 124, 126, 128, 130, 131, 132, 134, 135, 137, 138, 144, 146, 149, 150, 151, 152, 153, 155, 156, 158, 161, 162, 163, 164, 165, 166, 167, 168, 169, 171, 172, 174, 175, 176, 179, 181, 182, 183, 184, 186, 187, 188, 189, 190, 191, 193, 194, 196, 197, 199, 200, 202, 203, 204, 205, 206, 207, 210, 212, 213, 214, 215, 216, 219, 220, 222, 223, 227, 229, 230, 231, 232, 235, 236, 237, 239, 241, 242, 245, 247, 248, 249, 251, 252, 254, 255, 257, 258, 261, 262, 263, 265, 267, 268, 269, 270, 271, 273, 275, 277, 278, 280, 281, 284, 288, 289, 291, 294, 299, 301, 302, 304, 307, 308, 309, 310, 311, 316, 318, 322, 323, 324, 327, 329, 333, 335, 336, 340, 342, 348, 353, 355, 358, 359, 361, 363, 364, 366, 367, 368, 369, 370, 372, 373, 374, 375, 376, 378, 382, 384, 385, 386, 387, 392, 400, 402, 403, 407, 408, 412, 413, 416, 417, 422, 423, 424, 425, 426, 427, 428, 429, 432, 433, 434, 435, 441, 444, 447, 448, 449, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462]\n",
      "Cantidad de estaciones: 275\n",
      "[2, 3, 4, 5, 6, 7, 8, 9, 12, 13, 14, 17, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 35, 36, 38, 41, 43, 44, 45, 46, 48, 49, 50, 51, 54, 56, 57, 58, 59, 60, 61, 63, 64, 65, 66, 68, 69, 70, 71, 73, 74, 75, 76, 77, 79, 80, 82, 83, 84, 85, 86, 87, 89, 91, 92, 93, 94, 95, 96, 98, 99, 101, 102, 104, 107, 111, 112, 114, 116, 117, 118, 120, 121, 122, 124, 126, 128, 130, 131, 132, 134, 135, 137, 138, 144, 146, 149, 150, 151, 152, 153, 155, 156, 158, 161, 162, 163, 164, 165, 166, 167, 168, 169, 171, 172, 174, 175, 176, 177, 179, 181, 182, 183, 184, 186, 187, 188, 189, 190, 191, 193, 194, 196, 197, 199, 200, 202, 203, 204, 205, 206, 207, 208, 210, 212, 213, 214, 215, 216, 219, 220, 222, 223, 227, 228, 229, 230, 231, 232, 234, 235, 236, 237, 239, 241, 242, 245, 247, 248, 249, 251, 252, 253, 254, 255, 257, 258, 259, 260, 261, 262, 263, 265, 267, 268, 269, 270, 271, 273, 275, 277, 278, 280, 281, 284, 289, 291, 294, 299, 301, 302, 304, 307, 308, 309, 310, 311, 316, 318, 322, 323, 324, 327, 329, 330, 333, 335, 336, 337, 340, 342, 348, 349, 353, 355, 358, 359, 361, 362, 363, 364, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 378, 379, 381, 382, 383, 384, 385, 386, 387, 392, 393, 395, 400, 403, 407, 408, 412, 413, 416, 417, 418, 419, 420, 422, 423, 424, 425, 426, 427, 428, 429, 431, 432, 433, 434, 435, 436, 440, 441, 442, 443, 444, 447, 448, 449, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 464, 465, 466, 467, 468, 469, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 496, 497, 498]\n",
      "Cantidad de estaciones: 334\n",
      "[2, 3, 4, 5, 6, 7, 8, 9, 12, 13, 14, 17, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31, 32, 33, 35, 36, 38, 41, 43, 44, 45, 46, 48, 49, 50, 51, 54, 56, 57, 58, 59, 60, 61, 63, 64, 65, 66, 68, 69, 70, 71, 73, 74, 75, 76, 77, 79, 80, 82, 83, 85, 86, 87, 89, 91, 92, 93, 94, 95, 96, 98, 99, 101, 102, 104, 107, 111, 112, 114, 116, 117, 118, 120, 121, 122, 124, 126, 128, 130, 131, 132, 134, 135, 137, 138, 144, 146, 148, 149, 150, 151, 152, 153, 155, 156, 158, 161, 162, 163, 164, 165, 166, 167, 168, 169, 171, 172, 174, 175, 176, 177, 179, 181, 182, 183, 184, 186, 187, 188, 189, 190, 191, 193, 194, 196, 197, 199, 200, 202, 203, 204, 205, 206, 207, 208, 210, 212, 213, 215, 216, 219, 220, 222, 223, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 239, 241, 242, 245, 247, 248, 251, 252, 253, 254, 255, 257, 258, 259, 260, 261, 262, 263, 264, 265, 267, 268, 269, 270, 271, 273, 275, 277, 278, 280, 281, 284, 289, 291, 299, 301, 302, 304, 307, 308, 309, 310, 311, 313, 316, 318, 322, 323, 324, 327, 329, 330, 333, 335, 336, 340, 342, 348, 349, 353, 355, 358, 359, 361, 362, 363, 364, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 378, 379, 381, 382, 383, 384, 385, 386, 387, 392, 393, 395, 400, 403, 407, 408, 412, 413, 414, 416, 417, 418, 420, 422, 423, 424, 425, 426, 427, 428, 429, 431, 432, 433, 434, 435, 436, 440, 441, 443, 444, 448, 449, 453, 454, 455, 457, 458, 459, 460, 461, 464, 465, 466, 467, 468, 469, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 511, 512, 513, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538]\n",
      "Cantidad de estaciones: 365\n",
      "[2, 3, 4, 5, 6, 7, 8, 9, 12, 13, 14, 17, 21, 22, 23, 24, 25, 26, 27, 29, 32, 33, 35, 36, 38, 41, 43, 44, 45, 46, 48, 49, 50, 51, 54, 56, 57, 58, 59, 60, 61, 63, 64, 65, 66, 68, 69, 70, 71, 73, 74, 75, 76, 77, 79, 80, 82, 83, 85, 86, 87, 89, 91, 92, 93, 94, 96, 98, 99, 101, 102, 104, 107, 111, 112, 114, 116, 117, 118, 120, 121, 122, 124, 126, 128, 130, 131, 132, 134, 135, 137, 138, 144, 146, 148, 149, 150, 151, 152, 153, 155, 156, 158, 161, 162, 163, 164, 165, 166, 167, 168, 169, 171, 172, 174, 175, 176, 177, 179, 181, 182, 183, 184, 186, 187, 188, 189, 190, 191, 193, 194, 196, 197, 199, 200, 202, 203, 204, 206, 207, 208, 210, 212, 213, 215, 216, 219, 220, 222, 223, 227, 228, 229, 230, 231, 232, 234, 235, 236, 237, 239, 241, 242, 245, 247, 248, 251, 252, 253, 254, 255, 257, 258, 259, 260, 261, 262, 263, 264, 265, 267, 268, 269, 270, 271, 273, 275, 277, 278, 280, 281, 284, 289, 291, 299, 301, 302, 304, 307, 308, 309, 310, 311, 313, 316, 318, 322, 323, 324, 327, 329, 330, 333, 335, 336, 340, 342, 348, 349, 353, 355, 358, 359, 361, 362, 363, 364, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 378, 379, 381, 382, 383, 384, 385, 386, 387, 392, 393, 395, 400, 402, 403, 407, 408, 412, 413, 414, 416, 417, 418, 420, 422, 423, 424, 425, 426, 427, 428, 429, 431, 432, 433, 434, 435, 436, 440, 441, 443, 444, 448, 449, 453, 454, 455, 457, 458, 460, 461, 464, 465, 466, 467, 468, 469, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 511, 512, 513, 515, 516, 517, 518, 519, 520, 521, 522, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 556]\n",
      "Cantidad de estaciones: 376\n"
     ]
    }
   ],
   "source": [
    "# Eliminar filas con NaN solo en las columnas de estaciones\n",
    "df_2021_filtrado = df_trips_2021.dropna(subset=['id_estacion_origen', 'id_estacion_destino'])\n",
    "\n",
    "# Crear conjunto de estaciones únicas\n",
    "estaciones_2021 = sorted(set(df_2021_filtrado['id_estacion_origen']).union(\n",
    "                    set(df_2021_filtrado['id_estacion_destino'])))\n",
    "\n",
    "n_est_2021 = len(estaciones_2021)\n",
    "print(estaciones_2021)\n",
    "print(f'Cantidad de estaciones: {n_est_2021}')\n",
    "\n",
    "\n",
    "\n",
    "# Eliminar filas con NaN solo en las columnas de estaciones\n",
    "df_2022_filtrado = df_trips_2022.dropna(subset=['id_estacion_origen', 'id_estacion_destino'])\n",
    "\n",
    "# Crear conjunto de estaciones únicas\n",
    "estaciones_2022 = sorted(set(df_2022_filtrado['id_estacion_origen']).union(\n",
    "                    set(df_2022_filtrado['id_estacion_destino'])))\n",
    "\n",
    "n_est_2022 = len(estaciones_2022)\n",
    "print(estaciones_2022)\n",
    "print(f'Cantidad de estaciones: {n_est_2022}')\n",
    "\n",
    "\n",
    "\n",
    "# Eliminar filas con NaN solo en las columnas de estaciones\n",
    "df_2023_filtrado = df_trips_2023.dropna(subset=['id_estacion_origen', 'id_estacion_destino'])\n",
    "\n",
    "# Crear conjunto de estaciones únicas\n",
    "estaciones_2023 = sorted(set(df_2023_filtrado['id_estacion_origen']).union(\n",
    "                    set(df_2023_filtrado['id_estacion_destino'])))\n",
    "\n",
    "n_est_2023 = len(estaciones_2023)\n",
    "print(estaciones_2023)\n",
    "print(f'Cantidad de estaciones: {n_est_2023}')\n",
    "\n",
    "\n",
    "\n",
    "# Eliminar filas con NaN solo en las columnas de estaciones\n",
    "df_2024_filtrado = df_trips_2024.dropna(subset=['id_estacion_origen', 'id_estacion_destino'])\n",
    "\n",
    "# Crear conjunto de estaciones únicas\n",
    "estaciones_2024 = sorted(set(df_2024_filtrado['id_estacion_origen']).union(\n",
    "                    set(df_2024_filtrado['id_estacion_destino'])))\n",
    "\n",
    "n_est_2024 = len(estaciones_2024)\n",
    "print(estaciones_2024)\n",
    "print(f'Cantidad de estaciones: {n_est_2024}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad total de estaciones únicas (2020-2024): 501\n"
     ]
    }
   ],
   "source": [
    "estaciones_totales = set(estaciones).union(estaciones_2021, estaciones_2022, estaciones_2023, estaciones_2024)\n",
    "print(f\"Cantidad total de estaciones únicas (2020-2024): {len(estaciones_totales)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estaciones únicas de 2020: 103 → [11, 15, 19, 39, 40, 47, 52, 53, 55, 62, 72, 78, 88, 90, 106, 110, 115, 119, 127, 141, 143, 154, 170, 173, 180, 185, 192, 195, 201, 217, 218, 221, 224, 225, 226, 238, 240, 244, 246, 250, 256, 266, 272, 274, 276, 279, 282, 283, 285, 286, 287, 290, 292, 293, 295, 296, 297, 298, 300, 303, 305, 306, 312, 314, 317, 319, 320, 321, 325, 326, 328, 332, 338, 339, 341, 343, 345, 347, 350, 351, 352, 354, 356, 377, 380, 388, 389, 390, 391, 394, 396, 397, 398, 399, 401, 404, 405, 406, 409, 411, 415, 421, 430]\n",
      "Estaciones únicas de 2021: 0 → []\n",
      "Estaciones únicas de 2022: 0 → []\n",
      "Estaciones únicas de 2023: 1 → [523]\n",
      "Estaciones únicas de 2024: 17 → [539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 556]\n"
     ]
    }
   ],
   "source": [
    "solo_2020 = set(estaciones) - set(estaciones_2021) - set(estaciones_2022) - set(estaciones_2023) - set(estaciones_2024)\n",
    "print(f\"Estaciones únicas de 2020: {len(solo_2020)} → {sorted(solo_2020)}\")\n",
    "\n",
    "solo_2021 = set(estaciones_2021) - set(estaciones_2024) - set(estaciones_2022) - set(estaciones_2023) - set(estaciones)\n",
    "print(f\"Estaciones únicas de 2021: {len(solo_2021)} → {sorted(solo_2021)}\")\n",
    "\n",
    "solo_2022 = set(estaciones_2022) - set(estaciones_2021) - set(estaciones_2024) - set(estaciones_2023) - set(estaciones)\n",
    "print(f\"Estaciones únicas de 2022: {len(solo_2022)} → {sorted(solo_2022)}\")\n",
    "\n",
    "solo_2023 = set(estaciones_2023) - set(estaciones_2021) - set(estaciones_2022) - set(estaciones_2024) - set(estaciones)\n",
    "print(f\"Estaciones únicas de 2023: {len(solo_2023)} → {sorted(solo_2023)}\")\n",
    "\n",
    "solo_2024 = set(estaciones_2024) - set(estaciones_2021) - set(estaciones_2022) - set(estaciones_2023) - set(estaciones)\n",
    "print(f\"Estaciones únicas de 2024: {len(solo_2024)} → {sorted(solo_2024)}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
